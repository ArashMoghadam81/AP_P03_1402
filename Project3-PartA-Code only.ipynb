{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install yfinance --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from scipy.linalg import svd\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy import linalg\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Part of Project ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 & Q2-A&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stock symbol and date range\n",
    "symbol = 'INTC'  \n",
    "start_date = '2010-01-01'\n",
    "end_date = '2023-07-01'\n",
    "\n",
    "# Download data from Yahoo Finance\n",
    "Intel = yf.download(symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Save data to a CSV file\n",
    "# file_path1 = 'Intel_data.csv'\n",
    "# Intel.to_csv(file_path1, index=False)\n",
    "\n",
    "# Forward fill missing values\n",
    "Intel.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Sample the data to a daily frequency\n",
    "Intel = Intel.resample('D').last()\n",
    "\n",
    "# Fill missing values with linear interpolation\n",
    "Intel.interpolate(method='linear', inplace=True)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "file_path1 = 'Intel_data.csv'\n",
    "Intel.to_csv(file_path1, index=False)\n",
    "\n",
    "# Print the datas\n",
    "print(Intel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stock symbol and date range\n",
    "symbol = 'AMD'  \n",
    "start_date = '2010-01-01'\n",
    "end_date = '2023-07-01'\n",
    "\n",
    "# Download data from Yahoo Finance\n",
    "AMD = yf.download(symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Save data to a CSV file\n",
    "# file_path2 = 'AMD_data.csv'\n",
    "# AMD.to_csv(file_path2, index=False)\n",
    "\n",
    "# Forward fill missing values\n",
    "AMD.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Sample the data to a daily frequency\n",
    "AMD = AMD.resample('D').last()\n",
    "\n",
    "# Fill missing values with linear interpolation\n",
    "AMD.interpolate(method='linear', inplace=True)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "file_path2 = 'AMD_data.csv'\n",
    "AMD.to_csv(file_path2, index=False)\n",
    "\n",
    "# Print the data\n",
    "print(AMD)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-B Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding missing values qty\n",
    "missing_values_Intel = Intel.isnull().sum()\n",
    "missing_values_AMD = AMD.isnull().sum()\n",
    "print(missing_values_Intel)\n",
    "print('\\n')\n",
    "print(missing_values_AMD)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(Data):\n",
    "\n",
    "    normalized_data = (Data - np.mean(Data, axis=0)) / np.std(Data, axis=0)\n",
    "\n",
    "    # Create a new DataFrame with the normalized values\n",
    "    normalized_data = pd.DataFrame(normalized_data, columns=Data.columns)\n",
    "\n",
    "    return normalized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the normalize_csv function\n",
    "norm_data_Intel = normalize_data(Intel)\n",
    "norm_data_AMD = normalize_data(AMD)\n",
    "\n",
    "# Print the normalized data\n",
    "print('Intel Normalized')\n",
    "print(norm_data_Intel)\n",
    "print('\\n')\n",
    "print('AMD Normalized')\n",
    "print(norm_data_AMD)\n",
    "\n",
    "# norm_data_Intel.describe()\n",
    "# norm_data_AMD.describe()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stationarity transformation (differencing) for close prices\n",
    "Close_diff_Intel = norm_data_Intel.diff()\n",
    "Close_diff_Intel.dropna(inplace=True)\n",
    "\n",
    "print(Close_diff_Intel)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Perform stationarity transformation (differencing) for close prices\n",
    "Close_diff_AMD = norm_data_AMD.diff()\n",
    "Close_diff_AMD.dropna(inplace=True)\n",
    "\n",
    "print(Close_diff_AMD)\n",
    "\n",
    "# Seeing result on plot for close prices as an example\n",
    "plt.style.use('bmh')\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.figure(figsize=(15,6), dpi=500)\n",
    "Close_diff_Intel['Close'].plot(linewidth = 0.7)\n",
    "plt.title('Close', fontsize=20, fontweight='bold')\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Price\", fontsize=12)\n",
    "plt.grid(color = 'white', linestyle = '--', linewidth = 0.8)\n",
    "\n",
    "plt.figure(figsize=(15,6), dpi=500)\n",
    "Close_diff_AMD['Close'].plot(linewidth = 0.7)\n",
    "plt.title('Close', fontsize=20, fontweight='bold')\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Price\", fontsize=12)\n",
    "plt.grid(color = 'white', linestyle = '--', linewidth = 0.8)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = norm_data_Intel.columns\n",
    "\n",
    "# sns.set_theme()\n",
    "plt.style.use('bmh')\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "for column_name in column_names:\n",
    "    plt.figure(figsize=(15,6), dpi=500)\n",
    "    plt.plot(norm_data_Intel[column_name], linewidth = 0.7)\n",
    "    plt.title(column_name, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(\"Date\", fontsize=12)\n",
    "    plt.ylabel(\"Price\", fontsize=12)\n",
    "    plt.grid(color = 'white', linestyle = '--', linewidth = 0.8)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = norm_data_AMD.columns\n",
    "\n",
    "plt.style.use('bmh')\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "for column_name in column_names:\n",
    "    plt.figure(figsize=(15,6), dpi=500)\n",
    "    plt.plot(norm_data_AMD[column_name], linewidth = 0.7)\n",
    "    plt.title(column_name, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(\"Date\", fontsize=12)\n",
    "    plt.ylabel(\"Price\", fontsize=12)\n",
    "    plt.grid(color = 'white', linestyle = '--', linewidth = 0.8)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3-B"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intel Share Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Intel['Year'] = Intel.index.year\n",
    "# print(Intel)\n",
    "pivot_table_intel = Intel.pivot_table(values=['Close','Adj Close','Volume'], index='Year', aggfunc=['mean','median','sum','max','min','std','var'])\n",
    "pivot_table_intel.style.background_gradient(cmap='BuGn')\n",
    "\n",
    "# pivot_table_intel\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AMD Share Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMD['Year'] = AMD.index.year\n",
    "# print(AMD)\n",
    "\n",
    "pivot_table_AMD = AMD.pivot_table(values=['Adj Close','Close','Volume'], index='Year', aggfunc=['mean','median','sum','max','min','std','var'])\n",
    "pivot_table_AMD.title = \"AMD Share\"\n",
    "pivot_table_AMD.style.bar(color='seagreen')\n",
    "\n",
    "# pivot_table_AMD\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_data_Intel['Year'] = Intel.index.year\n",
    "# norm_data_Intel = norm_data_Intel.drop('Year', axis=1)\n",
    "column_names = norm_data_Intel.columns\n",
    "name1=[]\n",
    "name2=[]\n",
    "\n",
    "\n",
    "for column_name1 in column_names:\n",
    "    for column_name2 in column_names:\n",
    "        if column_name1 != column_name2:\n",
    "            if column_name1 not in name2 or column_name2 not in name1:\n",
    "                \n",
    "                name1.append(column_name1)\n",
    "                name2.append(column_name2)\n",
    "                correlation = norm_data_Intel[column_name1].corr(norm_data_Intel[column_name2])\n",
    "                print(f'Correlation between {column_name1} and {column_name2}:', correlation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_data_AMD = norm_data_AMD.drop('Year', axis=1)\n",
    "column_names = norm_data_AMD.columns\n",
    "name1=[]\n",
    "name2=[]\n",
    "\n",
    "\n",
    "for column_name1 in column_names:\n",
    "    for column_name2 in column_names:\n",
    "        if column_name1 != column_name2:\n",
    "            if column_name1 not in name2 or column_name2 not in name1:\n",
    "                \n",
    "                name1.append(column_name1)\n",
    "                name2.append(column_name2)\n",
    "                correlation = norm_data_AMD[column_name1].corr(norm_data_AMD[column_name2])\n",
    "                print(f'Correlation between {column_name1} and {column_name2}:', correlation)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4-A-Part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Moving_intel_weekly = norm_data_Intel.copy()\n",
    "column_names = Moving_intel_weekly.columns\n",
    "\n",
    "for column_name in column_names:\n",
    "    \n",
    "    Moving_intel_weekly[column_name] = Moving_intel_weekly[column_name].rolling(window=7).mean()\n",
    "\n",
    "    \n",
    "Moving_intel_weekly.dropna(inplace=True)    \n",
    "Moving_intel_weekly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Moving_intel_seasonly = norm_data_Intel.copy()\n",
    "column_names = Moving_intel_seasonly.columns\n",
    "\n",
    "for column_name in column_names:\n",
    "    \n",
    "    Moving_intel_seasonly[column_name] = Moving_intel_seasonly[column_name].rolling(window=90).mean()\n",
    "\n",
    "\n",
    "Moving_intel_seasonly.dropna(inplace=True)    \n",
    "Moving_intel_seasonly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Moving_AMD_weekly = norm_data_AMD.copy()\n",
    "column_names = Moving_AMD_weekly.columns\n",
    "\n",
    "for column_name in column_names:\n",
    "    \n",
    "    Moving_AMD_weekly[column_name] = Moving_AMD_weekly[column_name].rolling(window=7).mean()\n",
    "\n",
    "    \n",
    "Moving_AMD_weekly.dropna(inplace=True)   \n",
    "Moving_AMD_weekly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Moving_AMD_seasonly = norm_data_AMD.copy()\n",
    "column_names = Moving_AMD_seasonly.columns\n",
    "\n",
    "for column_name in column_names:\n",
    "    \n",
    "    Moving_AMD_seasonly[column_name] = Moving_AMD_seasonly[column_name].rolling(window=90).mean()\n",
    "    \n",
    "    \n",
    "Moving_AMD_seasonly.dropna(inplace=True) \n",
    "Moving_AMD_seasonly\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4-A-Part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Moving_intel_monthly = norm_data_Intel.copy()\n",
    "column_names = Moving_intel_monthly.columns\n",
    "\n",
    "\n",
    "for column_name in column_names:\n",
    "    \n",
    "    plt.figure(figsize=(15, 6), dpi=500)\n",
    "    Moving_intel_monthly[column_name] = Moving_intel_monthly[column_name].rolling(window=30).mean()\n",
    "    plt.plot(norm_data_Intel.index, norm_data_Intel[column_name], label='Original', linewidth = 0.7)\n",
    "    plt.plot(Moving_intel_monthly.index, Moving_intel_monthly[column_name], label='30-day Moving Average', linewidth = 0.9, color='orange')\n",
    "    plt.title(f'Intel Share {column_name} with 30-day Moving Average', fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Price', fontsize=12)\n",
    "    plt.grid(color = 'white', linestyle = '--', linewidth = 0.8)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Moving_AMD_monthly = norm_data_AMD.copy()\n",
    "column_names = Moving_AMD_monthly.columns\n",
    "\n",
    "\n",
    "for column_name in column_names:\n",
    "    \n",
    "    plt.figure(figsize=(15, 6), dpi=500)\n",
    "    Moving_AMD_monthly[column_name] = Moving_AMD_monthly[column_name].rolling(window=30).mean()\n",
    "    plt.plot(norm_data_AMD.index, norm_data_AMD[column_name], label='Original', linewidth = 0.7)\n",
    "    plt.plot(Moving_AMD_monthly.index, Moving_AMD_monthly[column_name], label='30-day Moving Average', linewidth = 0.9, color='orange')\n",
    "    plt.title(f'AMD Share {column_name} with 30-day Moving Average', fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Price', fontsize=12)\n",
    "    plt.grid(color = 'white', linestyle = '--', linewidth = 0.8)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_Intel = norm_data_Intel.copy()\n",
    "sample_Intel['Year'] = sample_Intel.index.year\n",
    "sample_Intel['Month'] = sample_Intel.index.month\n",
    "\n",
    "# Moving_sample_seasonly = normalize_data(sample_Intel)\n",
    "column_names = sample_Intel.columns\n",
    "# print(norm_data_Intel)\n",
    "# print(column_names)\n",
    "\n",
    "\n",
    "for column_name in column_names[0:-2]:\n",
    "    \n",
    "    trend = sample_Intel.groupby(['Year', 'Month'])[column_name].mean() \n",
    "    trend = trend.unstack()\n",
    "    trend.plot(figsize=(25, 10))\n",
    "    plt.title(f'Intel Share {column_name} with 90-day Moving Average', fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Date', fontsize=15)\n",
    "    plt.ylabel('Price', fontsize=15)\n",
    "    plt.grid(color = 'white', linestyle = '--', linewidth = 0.8)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_AMD = norm_data_AMD.copy()\n",
    "sample_AMD['Year'] = sample_AMD.index.year\n",
    "sample_AMD['Month'] = sample_AMD.index.month\n",
    "\n",
    "# Moving_sample_seasonly1 = normalize_data(sample_AMD)\n",
    "column_names = sample_AMD.columns\n",
    "# print(norm_data_AMD)\n",
    "# print(column_names)\n",
    "\n",
    "for column_name in column_names[0:-2]:\n",
    "    \n",
    "    trend = sample_AMD.groupby(['Year', 'Month'])[column_name].mean() \n",
    "    trend = trend.unstack()\n",
    "    trend.plot(figsize=(25, 10))\n",
    "    plt.title(f'AMD Share {column_name} with 90-day Moving Average', fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Date', fontsize=15)\n",
    "    plt.ylabel('Price', fontsize=15)\n",
    "    plt.grid(color = 'white', linestyle = '--', linewidth = 0.8)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(Data):\n",
    "\n",
    "    normalized = (Data - np.mean(Data, axis=0)) / np.std(Data, axis=0)\n",
    "\n",
    "    # Create a new DataFrame with the normalized values\n",
    "    normalized_data = pd.DataFrame(normalized, columns=Data.columns)\n",
    "\n",
    "    return normalized_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2013-01-01'\n",
    "end_date = '2023-07-01'\n",
    "\n",
    "\n",
    "def get(import_list):\n",
    "    \n",
    "    for item in import_list:\n",
    "                   \n",
    "        print('\\n')\n",
    "        print(item)\n",
    "        slot = yf.download(item, start=start_date, end=end_date)\n",
    "        slot = pd.DataFrame(slot, columns=slot.columns)\n",
    "        slot.fillna(method='ffill', inplace=True)\n",
    "\n",
    "        # Sample the data to a daily frequency\n",
    "        slot = slot.resample('D').last()\n",
    "\n",
    "        # Fill missing values with linear interpolation\n",
    "        slot.interpolate(method='linear', inplace=True)\n",
    "\n",
    "        if slot['Volume'].sum() == 0:   \n",
    "                slot = slot.drop('Volume', axis=1)\n",
    "                print(slot)\n",
    "\n",
    "        else:\n",
    "                print(slot)\n",
    "\n",
    "import_list = ['EURUSD=X', 'USDSAR=X', 'USDCNY=X', '^IRX', 'BTC-USD', 'GC=F', 'HG=F', 'ZW=F']\n",
    "get(import_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2013-01-01'\n",
    "end_date = '2023-07-01'\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    normalized = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "    normalized_data = pd.DataFrame(normalized, columns=data.columns)\n",
    "    \n",
    "    return normalized_data\n",
    "\n",
    "def apply_pca(datas, n_components):\n",
    "    # Remove rows with missing values\n",
    "    datas = datas.dropna()\n",
    "    \n",
    "    # Perform Singular Value Decomposition (SVD)\n",
    "    U, S, V = svd(datas, full_matrices=False)\n",
    "    \n",
    "    # Select the top 'n_components' singular vectors\n",
    "    reduced_data = np.dot(datas, V.T[:, :n_components])\n",
    "    columns = [f\"PC{i+1}\" for i in range(n_components)]\n",
    "    reduced_df = pd.DataFrame(reduced_data, columns=columns)\n",
    "    \n",
    "    return reduced_df\n",
    "\n",
    "def PCA(import_list):\n",
    "    for item in import_list:\n",
    "        \n",
    "            print('\\n')\n",
    "            print(item)\n",
    "            slot = yf.download(item, start=start_date, end=end_date)\n",
    "            slot = pd.DataFrame(slot, columns=slot.columns)\n",
    "            slot.fillna(method='ffill', inplace=True)\n",
    "\n",
    "            # Sample the data to a daily frequency\n",
    "            slot = slot.resample('D').last()\n",
    "\n",
    "            # Fill missing values with linear interpolation\n",
    "            slot.interpolate(method='linear', inplace=True)\n",
    "\n",
    "            if slot['Volume'].sum() == 0:   \n",
    "                slot = slot.drop('Volume', axis=1)\n",
    "                    \n",
    "            # iris = load_iris()\n",
    "            # data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "            normalized_data = normalize(slot)\n",
    "\n",
    "            # Apply PCA using Truncated SVD to decrease dimensions\n",
    "            n_components = 2  # Number of dimensions/components after PCA\n",
    "            reduced_data = apply_pca(normalized_data, n_components)\n",
    "\n",
    "            # Print the reduced data\n",
    "            print(f'PCA for {item}')\n",
    "            print(reduced_data)\n",
    "\n",
    "\n",
    "import_list = ['EURUSD=X', 'USDSAR=X', 'USDCNY=X', '^IRX', 'BTC-USD', 'GC=F', 'HG=F', 'ZW=F']\n",
    "PCA(import_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2013-01-01'\n",
    "end_date = '2023-07-01'\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    normalized = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "    normalized_data = pd.DataFrame(normalized, columns=data.columns)\n",
    "    \n",
    "    return normalized_data\n",
    "\n",
    "def apply_pca(datas, n_components):\n",
    "    # Remove rows with missing values\n",
    "    datas = datas.dropna()\n",
    "    \n",
    "    # Perform Singular Value Decomposition (SVD)\n",
    "    U, S, V = svd(datas, full_matrices=False)\n",
    "    \n",
    "    # Select the top 'n_components' singular vectors\n",
    "    reduced_data = np.dot(datas, V.T[:, :n_components])\n",
    "    \n",
    "    explained_variance_ratio = (S ** 2) / np.sum(S ** 2)\n",
    "    # explained_variance_ratio = (S[0] ** 2) / np.sum(S ** 2)        \n",
    "    columns = [f\"PC{i+1}\" for i in range(n_components)]\n",
    "    reduced_df = pd.DataFrame(reduced_data, columns=columns)\n",
    "    \n",
    "    return explained_variance_ratio\n",
    "\n",
    "def PCA(import_list):\n",
    "    for item in import_list:\n",
    "        \n",
    "            print('\\n')\n",
    "            print(item)\n",
    "            slot = yf.download(item, start=start_date, end=end_date)\n",
    "            slot = pd.DataFrame(slot, columns=slot.columns)\n",
    "            slot.fillna(method='ffill', inplace=True)\n",
    "\n",
    "            # Sample the data to a daily frequency\n",
    "            slot = slot.resample('D').last()\n",
    "\n",
    "            # Fill missing values with linear interpolation\n",
    "            slot.interpolate(method='linear', inplace=True)\n",
    "\n",
    "            if slot['Volume'].sum() == 0:   \n",
    "                    slot = slot.drop('Volume', axis=1)\n",
    "                    \n",
    "            # iris = load_iris()\n",
    "            # data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "            normalized_data = normalize(slot)\n",
    "\n",
    "            # Apply PCA using Truncated SVD to decrease dimensions\n",
    "            n_components = 2  # Number of dimensions/components after PCA\n",
    "            explained_variance_ratio = apply_pca(normalized_data, n_components)\n",
    "\n",
    "            print(f\"Explained Variance Ratio for {item}:\")\n",
    "            explained_variance_str = \", \".join([f\"{ratio:.3f}\" for ratio in explained_variance_ratio])\n",
    "            print(f\"PCA: {explained_variance_str}\")\n",
    "\n",
    "\n",
    "\n",
    "import_list = ['EURUSD=X', 'USDSAR=X', 'USDCNY=X', '^IRX', 'BTC-USD', 'GC=F', 'HG=F', 'ZW=F']\n",
    "PCA(import_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2013-01-01'\n",
    "end_date = '2023-07-01'\n",
    "\n",
    "def normalize(data):\n",
    "    normalized = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "    normalized_data = pd.DataFrame(normalized, columns=data.columns)\n",
    "    return normalized_data\n",
    "\n",
    "def apply_pca(datas, n_components):\n",
    "    # Remove rows with missing values\n",
    "    datas = datas.dropna()\n",
    "    \n",
    "    # Perform Singular Value Decomposition (SVD)\n",
    "    U, S, V = svd(datas, full_matrices=False)\n",
    "    \n",
    "    # Select the top 'n_components' singular vectors\n",
    "    reduced_data = np.dot(datas, V.T[:, :n_components])\n",
    "    \n",
    "    explained_variance_ratio = (S ** 2) / np.sum(S ** 2)\n",
    "    \n",
    "    columns = [f\"PC{i+1}\" for i in range(n_components)]\n",
    "    reduced_df = pd.DataFrame(reduced_data, columns=columns)\n",
    "    \n",
    "    return explained_variance_ratio, V\n",
    "\n",
    "\n",
    "def PCA(import_list):\n",
    "    for item in import_list:\n",
    "        \n",
    "        print('\\n')\n",
    "        print(item)\n",
    "        slot = yf.download(item, start=start_date, end=end_date)\n",
    "        slot = pd.DataFrame(slot, columns=slot.columns)\n",
    "        slot.fillna(method='ffill', inplace=True)\n",
    "\n",
    "        # Sample the data to a daily frequency\n",
    "        slot = slot.resample('D').last()\n",
    "\n",
    "        # Fill missing values with linear interpolation\n",
    "        slot.interpolate(method='linear', inplace=True)\n",
    "\n",
    "        if slot['Volume'].sum() == 0:\n",
    "            slot = slot.drop('Volume', axis=1)\n",
    "\n",
    "        normalized_data = normalize(slot)\n",
    "\n",
    "        # Apply PCA using Truncated SVD to decrease dimensions\n",
    "        n_components = 2  # Number of dimensions/components after PCA\n",
    "        explained_variance_ratio, principal_components = apply_pca(normalized_data, n_components)\n",
    "\n",
    "        print(f\"Explained Variance Ratio for {item}:\")\n",
    "        explained_variance_str = \", \".join([f\"{ratio:.3f}\" for ratio in explained_variance_ratio])\n",
    "        print(f\"PCA1: {explained_variance_str}\")\n",
    "\n",
    "        # Create a scree plot\n",
    "        plt.figure(figsize=(15, 6), dpi=500)\n",
    "        plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o', linewidth = 0.9)\n",
    "        plt.xlabel('Principal Component', fontsize=12)\n",
    "        plt.ylabel('Variance Explained Ratio', fontsize=12)\n",
    "        plt.title(f\"Scree Plot for {item}\", fontsize=20, fontweight='bold')\n",
    "        plt.grid(color = 'white', linestyle = '--', linewidth = 0.8)\n",
    "        plt.show()\n",
    "\n",
    "        # # Create a biplot\n",
    "        # feature_names = normalized_data.columns\n",
    "        # plt.figure(figsize=(15, 6), dpi=500)\n",
    "        # plt.grid(color = 'white', linestyle = '--', linewidth = 0.8, alpha=0.8)\n",
    "        \n",
    "        # from itertools import cycle\n",
    "        # cycol = cycle('bgrcmk')\n",
    "\n",
    "        # color_legend = []\n",
    "        # position = ['left', 'right', 'center', 'right', 'center', 'left']\n",
    "        # j = 0\n",
    "        \n",
    "        # for i, feature in enumerate(feature_names):\n",
    "            \n",
    "        #     color = plt.plot(0, 0, color = next(cycol), alpha=0.5, linewidth=0.9, label=feature)\n",
    "        #     color_legend.append(color[0])\n",
    "        #     plt.arrow(0, 0, principal_components[0, i], principal_components[1, i], color=color[0].get_color(), alpha=0.5, linewidth=0.9)\n",
    "        #     plt.text(principal_components[0, i]*1.1, principal_components[1, i]*1.1, feature, color=color[0].get_color(), rotation = 20, rotation_mode='anchor', ha = position[j])\n",
    "        #     # plt.text(principal_components[0, i]*1.1, principal_components[1, i]*1.1, feature, color=color[0].get_color())\n",
    "        #     j += 1\n",
    "        \n",
    "        # plt.legend(handles=color_legend)\n",
    "            \n",
    "        # plt.xlim(-1.25, 1.25)\n",
    "        # plt.ylim(-1.25, 1.25)\n",
    "        # plt.xlabel('PC1', fontsize=12)\n",
    "        # plt.ylabel('PC2', fontsize=12)\n",
    "        # plt.title(f\"Biplot for {item}\", fontsize=20, fontweight='bold')\n",
    "        # plt.grid(color = 'white', linestyle = '--', linewidth = 0.8, alpha=0.5)\n",
    "        # plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "import_list = ['EURUSD=X', 'USDSAR=X', 'USDCNY=X', '^IRX', 'BTC-USD', 'GC=F', 'HG=F', 'ZW=F']\n",
    "PCA(import_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stock symbols and date range\n",
    "import_list = ['EURUSD=X', 'USDSAR=X', 'USDCNY=X', '^IRX', 'BTC-USD', 'GC=F', 'HG=F', 'ZW=F']\n",
    "start_date = '2013-01-01'\n",
    "end_date = '2023-07-01'\n",
    "\n",
    "def normalize(data):\n",
    "    normalized = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "    return normalized\n",
    "\n",
    "def apply_pca(datas, n_components):\n",
    "    datas_centered = datas - np.mean(datas, axis=0)\n",
    "    covariance_matrix = np.cov(datas_centered.T)\n",
    "    eigenvalues, eigenvectors = linalg.eig(covariance_matrix)\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues_sorted = eigenvalues[sorted_indices]\n",
    "    eigenvectors_sorted = eigenvectors[:, sorted_indices]\n",
    "    selected_eigenvectors = eigenvectors_sorted[:, :n_components]\n",
    "    transformed_data = np.dot(datas_centered, selected_eigenvectors)\n",
    "    return transformed_data, selected_eigenvectors, eigenvalues_sorted\n",
    "\n",
    "for item in import_list:\n",
    "    print('\\n')\n",
    "    print(item)\n",
    "    \n",
    "    # Download data from Yahoo Finance\n",
    "    slot = yf.download(item, start=start_date, end=end_date)\n",
    "    slot = pd.DataFrame(slot, columns=slot.columns)\n",
    "    slot.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Sample the data to a daily frequency\n",
    "    slot = slot.resample('D').last()\n",
    "\n",
    "    # Fill missing values with linear interpolation\n",
    "    slot.interpolate(method='linear', inplace=True)\n",
    "    \n",
    "    if slot['Volume'].sum() == 0:\n",
    "        slot = slot.drop('Volume', axis=1)\n",
    "\n",
    "    # Normalize the data\n",
    "    normalized_data = normalize(slot.values)\n",
    "\n",
    "    # Apply PCA\n",
    "    num_components = 2  # Number of components after PCA\n",
    "    transformed_data, eigenvectors, eigenvalues = apply_pca(normalized_data, num_components)\n",
    "\n",
    "    # Plot the PCA transformed data\n",
    "    fig, ax = plt.subplots(figsize=(28, 15))\n",
    "    # plt.figure(, dpi=500)\n",
    "    sc = ax.scatter(transformed_data[:, 0], transformed_data[:, 1], c=np.arange(len(transformed_data)), cmap='viridis')\n",
    "    plt.xlabel('Principal Component 1', fontsize=10)\n",
    "    plt.ylabel('Principal Component 2', fontsize=10)\n",
    "    plt.title(f'PCA - {item}', fontsize=17, fontweight='bold')\n",
    "    \n",
    "    # Plot the eigenvectors as arrows with eigenvalue labels\n",
    "    origin = np.mean(transformed_data, axis=0)\n",
    "    \n",
    "    for i in range(num_components):\n",
    "        \n",
    "        ax.arrow(origin[0], origin[1], eigenvectors[0, i], eigenvectors[1, i], color='r',\n",
    "                  width=0.1, head_width=0.3)\n",
    "        ax.text(origin[0] + eigenvectors[0, i], origin[1] + eigenvectors[1, i],\n",
    "                f\"λ{i+1} = {eigenvalues[i]:.2f}\", fontsize=12)\n",
    "    \n",
    "    # Add a colorbar\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label('Data Point Index')\n",
    "    plt.grid(color = 'white', linestyle = '--', linewidth = 0.8, alpha=0.8)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
